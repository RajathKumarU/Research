Big Data: A Survey titlerpIn this paper, we review the background and
state-of-the-art of big data. We first introduce the general
background of big data and review related technologies,
such as could computing, Internet of Things, data centers,
and Hadoop. We then focus on the four phases of the value
chain of big data, i.e., data generation, data acquisition, data
storage, and data analysis. For each phase, we introduce the
general background, discuss the technical challenges, and
review the latest advances. We finally examine the several
representative applications of big data, including enterprise
management, Internet of Things, online social networks,
medial applications, collective intelligence, and smart grid.
These discussions aim to provide a comprehensive overview
and big-picture to readers of this exciting area. This survey
is concluded with a discussion of open problems and future
directions.abstractrpBig data · Cloud computing · Internet of
things · Data center · Hadoop · Smart grid · Big data
analysiskeywordsrpOver the past 20 years, data has increased in a large scale
in various fields. According to a report from International
Data Corporation (IDC), in 2011, the overall created and
copied data volume in the world was 1.8ZB (˜ 1021B),
which increased by nearly nine times within five years [1].
This figure will double at least every other two years in the
near future.
Under the explosive increase of global data, the term of
big data is mainly used to describe enormous datasets. Compared
with traditional datasets, big data typically includes
masses of unstructured data that need more real-time analysis.
In addition, big data also brings about new opportunities
for discovering new values, helps us to gain an in-depth
understanding of the hidden values, and also incurs new
challenges, e.g., how to effectively organize and manage
such datasets.
Recently, industries become interested in the high potential
of big data, and many government agencies announced
major plans to accelerate big data research and applications
[2]. In addition, issues on big data are often covered
in public media, such as The Economist [3, 4], New York
Times [5], and National Public Radio [6, 7]. Two premier
scientific journals, Nature and Science, also opened
special columns to discuss the challenges and impacts of
big data [8, 9]. The era of big data has come beyond all
doubt [10].
Nowadays, big data related to the service of Internet companies
grow rapidly. For example, Google processes data of
hundreds of Petabyte (PB), Facebook generates log data of
over 10 PB per month, Baidu, a Chinese company, processes
data of tens of PB, and Taobao, a subsidiary of Alibaba,
Mobile Netw Appl (2014) 19:171–209
DOI 10.1007/s11036-013-0489-0
generates data of tens of Terabyte (TB) for online trading
per day. Figure 1 illustrates the boom of the global data volume.
While the amount of large datasets is drastically rising,
it also brings about many challenging problems demanding
prompt solutions:
The latest advances of information technology (IT)
make it more easily to generate data. For example, on
average, 72 hours of videos are uploaded to YouTube
in every minute [11]. Therefore, we are confronted with
themain challenge of collecting and integratingmassive
data from widely distributed data sources.
The rapid growth of cloud computing and the Internet of
Things (IoT) further promote the sharp growth of data.
Cloud computing provides safeguarding, access sites
and channels for data asset. In the paradigm of IoT, sensors
all over the world are collecting and transmitting
data to be stored and processed in the cloud. Such data
in both quantity and mutual relations will far surpass
the capacities of the IT architectures and infrastructure
of existing enterprises, and its realtime requirement
will also greatly stress the available computing capacity.
The increasingly growing data cause a problem of how
to store and manage such huge heterogeneous datasets
with moderate requirements on hardware and software
infrastructure.
In consideration of the heterogeneity, scalability, realtime,
complexity, and privacy of big data, we shall
effectively “mine” the datasets at different levels during
the analysis, modeling, visualization, and forecasting,
so as to reveal its intrinsic property and improve the
decision making.
1.2 Definition and features of big data
Big data is an abstract concept. Apart from masses of data,
it also has some other features, which determine the difference
between itself and “massive data” or “very big data.”At present, although the importance of big data has been
generally recognized, people still have different opinions on
its definition. In general, big data shall mean the datasets
that could not be perceived, acquired, managed, and processed
by traditional IT and software/hardware tools within
a tolerable time. Because of different concerns, scientific
and technological enterprises, research scholars, data analysts,
and technical practitioners have different definitions
of big data. The following definitions may help us have a
better understanding on the profound social, economic, and
technological connotations of big data.
In 2010, Apache Hadoop defined big data as “datasets
which could not be captured, managed, and processed by
general computers within an acceptable scope.” On the basis
of this definition, in May 2011, McKinsey & Company, a
global consulting agency announced Big Data as the next
frontier for innovation, competition, and productivity. Big
data shall mean such datasets which could not be acquired,
stored, and managed by classic database software. This definition
includes two connotations: First, datasets’ volumes
that conform to the standard of big data are changing, and
may grow over time or with technological advances; Second,
datasets’ volumes that conform to the standard of big
data in different applications differ from each other. At
present, big data generally ranges from several TB to several
PB [10]. From the definition byMcKinsey & Company,
it can be seen that the volume of a dataset is not the only
criterion for big data. The increasingly growing data scale
and its management that could not be handled by traditional
database technologies are the next two key features.
As a matter of fact, big data has been defined as early
as 2001. Doug Laney, an analyst of META (presently
Gartner) defined challenges and opportunities brought about
by increased data with a 3Vs model, i.e., the increase of
Volume, Velocity, and Variety, in a research report [12].
Although such a model was not originally used to define
big data, Gartner and many other enterprises, including
IBM [13] and some research departments of Microsoft [14]
still used the “3Vs” model to describe big data within
the following ten years [15]. In the “3Vs” model, Volume
means, with the generation and collection of masses of
data, data scale becomes increasingly big; Velocity means
the timeliness of big data, specifically, data collection and
analysis, etc. must be rapidly and timely conducted, so as
to maximumly utilize the commercial value of big data;
Variety indicates the various types of data, which include
semi-structured and unstructured data such as audio, video,
webpage, and text, as well as traditional structured data.
However, others have different opinions, including IDC,
one of the most influential leaders in big data and its
research fields. In 2011, an IDC report defined big data as
“big data technologies describe a new generation of technologies
and architectures, designed to economically extract
value from very large volumes of a wide variety of data, by
enabling the high-velocity capture, discovery, and/or analysis.”
[1] With this definition, characteristics of big data
may be summarized as four Vs, i.e., Volume (great volume),
Variety (various modalities), Velocity (rapid generation),
and Value (huge value but very low density), as shown in
Fig. 2. Such 4Vs definition was widely recognized since
it highlights the meaning and necessity of big data, i.e.,
exploring the huge hidden values. This definition indicates
the most critical problem in big data, which is how to discover
values from datasets with an enormous scale, various
types, and rapid generation. As Jay Parikh, Deputy Chief
Engineer of Facebook, said, “You could only own a bunch
of data other than big data if you do not utilize the collected
data.” [11]
In addition, NIST defines big data as “Big data shall
mean the data of which the data volume, acquisition speed,
or data representation limits the capacity of using traditional
relational methods to conduct effective analysis or the data
which may be effectively processed with important horizontal
zoom technologies”, which focuses on the technological
aspect of big data. It indicates that efficient methods or
technologies need to be developed and used to analyze and
process big data.
There have been considerable discussions from both
industry and academia on the definition of big data [16, 17].
In addition to developing a proper definition, the big data
research should also focus on how to extract its value, how
to use data, and how to transform “a bunch of data” into “big
data.”
1.3 Big data value
McKinsey & Company observed how big data created values
after in-depth research on the U.S. healthcare, the EU
public sector administration, the U.S. retail, the global manufacturing,
and the global personal location data. Through
research on the five core industries that represent the global
economy, the McKinsey report pointed out that big data
may give a full play to the economic function, improve the
productivity and competitiveness of enterprises and public
sectors, and create huge benefits for consumers. In [10],
McKinsey summarized the values that big data could create:
if big data could be creatively and effectively utilized
to improve efficiency and quality, the potential value of
the U.S medical industry gained through data may surpass
USD 300 billion, thus reducing the expenditure for the U.S.
healthcare by over 8 %; retailers that fully utilize big data
may improve their profit by more than 60 %; big data may
also be utilized to improve the efficiency of government
operations, such that the developed economies in Europe
could save over EUR 100 billion (which excludes the effect
of reduced frauds, errors, and tax difference).The McKinsey report is regarded as prospective and
predictive, while the following facts may validate the values
of big data. During the 2009 flu pandemic, Google
obtained timely information by analyzing big data, which
even provided more valuable information than that provided
by disease prevention centers. Nearly all countries required
hospitals inform agencies such as disease prevention centers
of the new type of influenza cases. However, patients usually
did not see doctors immediately when they got infected.
It also took some time to send information from hospitals to
disease prevention centers, and for disease prevention centers
to analyze and summarize such information. Therefore,
when the public is aware of the pandemic of the new type
of influenza, the disease may have already spread for one to
two weeks with a hysteretic nature. Google found that during
the spreading of influenza, entries frequently sought at
its search engines would be different from those at ordinary
times, and the use frequencies of the entries were correlated
to the influenza spreading in both time and location.
Google found 45 search entry groups that were closely relevant
to the outbreak of influenza and incorporated them
in specific mathematic models to forecast the spreading of
influenza and even to predict places where influenza spread
from. The related research results have been published in
Nature [18].
In 2008, Microsoft purchased Farecast, a sci-tech venture
company in the U.S. Farecast has an airline ticket forecast
system that predicts the trends and rising/dropping ranges of
airline ticket price. The system has been incorporated into
the Bing search engine of Microsoft. By 2012, the system
has saved nearly USD 50 per ticket per passenger, with the
forecasted accuracy as high as 75 %.
At present, data has become an important production factor
that could be comparable to material assets and human
capital. As multimedia, social media, and IoT are developing,
enterprises will collect more information, leading
to an exponential growth of data volume. Big data will
have a huge and increasing potential in creating values for
businesses and consumers.
1.4 The development of big data
In the late 1970s, the concept of “database machine”
emerged, which is a technology specially used for storing
and analyzing data. With the increase of data volume,
the storage and processing capacity of a single mainframe
computer system became inadequate. In the 1980s, people
proposed “share nothing,” a parallel database system, to
meet the demand of the increasing data volume [19]. The
share nothing system architecture is based on the use of
cluster and every machine has its own processor, storage,
and disk. Teradata system was the first successful commercial
parallel database system. Such database became
very popular lately. On June 2, 1986, a milestone event
occurred when Teradata delivered the first parallel database
system with the storage capacity of 1TB to Kmart to help
the large-scale retail company in North America to expand
its data warehouse [20]. In the late 1990s, the advantages
of parallel database was widely recognized in the database
field.
However, many challenges on big data arose. With the
development of Internet servies, indexes and queried contents
were rapidly growing. Therefore, search engine companies
had to face the challenges of handling such big data.
Google created GFS [21] and MapReduce [22] programming
models to cope with the challenges brought about
by data management and analysis at the Internet scale. In
addition, contents generated by users, sensors, and other
ubiquitous data sources also feuled the overwhelming data
flows, which required a fundamental change on the computing
architecture and large-scale data processing mechanism.
In January 2007, Jim Gray, a pioneer of database software,
174 Mobile Netw Appl (2014) 19:171–209
called such transformation “The Fourth Paradigm” [23]. He
also thought the only way to cope with such paradigm was
to develop a new generation of computing tools to manage,
visualize, and analyze massive data. In June 2011, another
milestone event occurred; EMC/IDC published a research
report titled Extracting Values from Chaos [1], which introduced
the concept and potential of big data for the first
time. This research report triggered the great interest in both
industry and academia on big data.
Over the past few years, nearly all major companies,
including EMC, Oracle, IBM, Microsoft, Google, Amazon,
and Facebook, etc. have started their big data projects.
Taking IBM as an example, since 2005, IBM has invested
USD 16 billion on 30 acquisitions related to big data. In
academia, big data was also under the spotlight. In 2008,
Nature published a big data special issue. In 2011, Science
also launched a special issue on the key technologies of
“data processing” in big data. In 2012, European Research
Consortium for Informatics and Mathematics (ERCIM)
News published a special issue on big data. In the beginning
of 2012, a report titled Big Data, Big Impact presented at the
Davos Forum in Switzerland, announced that big data has
become a new kind of economic assets, just like currency
or gold. Gartner, an international research agency, issued
Hype Cycles from 2012 to 2013, which classified big data
computing, social analysis, and stored data analysis into 48
emerging technologies that deserve most attention.
Many national governments such as the U.S. also paid
great attention to big data. In March 2012, the Obama
Administration announced a USD 200 million investment
to launch the “Big Data Research and Development Plan,”
which was a second major scientific and technological
development initiative after the “Information Highway” initiative
in 1993. In July 2012, the “Vigorous ICT Japan”
project issued by Japan’s Ministry of Internal Affairs and
Communications indicated that the big data development
should be a national strategy and application technologies
should be the focus. In July 2012, the United Nations issued
Big Data for Development report, which summarized how
governments utilized big data to better serve and protect
their people.
1.5 Challenges of big data
The sharply increasing data deluge in the big data era
brings about huge challenges on data acquisition, storage,
management and analysis. Traditional data management
and analysis systems are based on the relational database
management system (RDBMS). However, such RDBMSs
only apply to structured data, other than semi-structured or
unstructured data. In addition, RDBMSs are increasingly
utilizing more and more expensive hardware. It is apparently
that the traditional RDBMSs could not handle the
huge volume and heterogeneity of big data. The research
community has proposed some solutions from different perspectives.
For example, cloud computing is utilized to meet
the requirements on infrastructure for big data, e.g., cost
efficiency, elasticity, and smooth upgrading/downgrading.
For solutions of permanent storage and management of
large-scale disordered datasets, distributed file systems [24]
and NoSQL [25] databases are good choices. Such programming
frameworks have achieved great success in processing
clustered tasks, especially for webpage ranking. Various big
data applications can be developed based on these innovative
technologies or platforms. Moreover, it is non-trivial to
deploy the big data analysis systems.
Some literature [26–28] discuss obstacles in the development
of big data applications. The key challenges are listed
as follows:
Data representation: many datasets have certain levels
of heterogeneity in type, structure, semantics, organization,
granularity, and accessibility. Data representation
aims to make data more meaningful for computer analysis
and user interpretation. Nevertheless, an improper
data representation will reduce the value of the original
data and may even obstruct effective data analysis.
Efficient data representation shall reflect data structure,
class, and type, as well as integrated technologies, so as
to enable efficient operations on different datasets.
Redundancy reduction and data compression: generally,
there is a high level of redundancy in datasets.
Redundancy reduction and data compression is effective
to reduce the indirect cost of the entire system on
the premise that the potential values of the data are not
affected. For example, most data generated by sensor
networks are highly redundant, which may be filtered
and compressed at orders of magnitude.
Data life cycle management: compared with the relatively
slow advances of storage systems, pervasive
sensing and computing are generating data at unprecedented
rates and scales. We are confronted with a lot
of pressing challenges, one of which is that the current
storage system could not support such massive data.
Generally speaking, values hidden in big data depend
on data freshness. Therefore, a data importance principle
related to the analytical value should be developed
to decide which data shall be stored and which data
shall be discarded.
Analytical mechanism: the analytical system of big data
shall process masses of heterogeneous data within a
limited time. However, traditional RDBMSs are strictly
designed with a lack of scalability and expandability,
which could not meet the performance requirements.
Non-relational databases have shown their unique
advantages in the processing of unstructured data and
Mobile Netw Appl (2014) 19:171–209 175
started to become mainstream in big data analysis.
Even so, there are still some problems of non-relational
databases in their performance and particular applications.
We shall find a compromising solution between
RDBMSs and non-relational databases. For example,
some enterprises have utilized a mixed database architecture
that integrates the advantages of both types of
database (e.g., Facebook and Taobao). More research
is needed on the in-memory database and sample data
based on approximate analysis.
Data confidentiality: most big data service providers or
owners at present could not effectively maintain and
analyze such huge datasets because of their limited
capacity. They must rely on professionals or tools to
analyze such data, which increase the potential safety
risks. For example, the transactional dataset generally
includes a set of complete operating data to drive key
business processes. Such data contains details of the
lowest granularity and some sensitive information such
as credit card numbers. Therefore, analysis of big data
may be delivered to a third party for processing only
when proper preventive measures are taken to protect
such sensitive data, to ensure its safety.
Energy management: the energy consumption of mainframe
computing systems has drawn much attention
from both economy and environment perspectives.With
the increase of data volume and analytical demands,
the processing, storage, and transmission of big data
will inevitably consume more and more electric energy.
Therefore, system-level power consumption control
and management mechanism shall be established for
big data while the expandability and accessibility are
ensured.
Expendability and scalability: the analytical system of
big data must support present and future datasets. The
analytical algorithm must be able to process increasingly
expanding and more complex datasets.
Cooperation: analysis of big data is an interdisciplinary
research, which requires experts in different
fields cooperate to harvest the potential of big data.
A comprehensive big data network architecture must
be established to help scientists and engineers in various
fields access different kinds of data and fully
utilize their expertise, so as to cooperate to complete the
analytical objectives.introductionrpIn this paper, we review the background and state-of-the-art
of big data. Firstly, we introduce the general background of
big data and review related technologies, such as could computing,
IoT, data centers, and Hadoop. Then we focus on the
four phases of the value chain of big data, i.e., data generation,
data acquisition, data storage, and data analysis. For
each phase, we introduce the general background, discuss
the technical challenges, and review the latest advances.
We finally reviewed the several representative applications
of big data, including enterprise management, IoT, social
networks, medical applications, collective intelligence, and
smart grid. These discussions aim to provide a comprehensive
overview and big-picture to readers of this exciting
area.
In the remainder of this section, we summarize the
research hot spots and suggest possible research directions
of big data.We also discuss potential development trends in
this broad research and application area.conclusionrp1. Gantz J, Reinsel D (2011) Extracting value from chaos. IDC
iView, pp 1–12
2. Fact sheet: Big data across the federal government (2012). http://
www.whitehouse.gov/sites/default/files/microsites/ostp/big data
fact sheet 3 29 2012.pdf
3. Cukier K (2010) Data, data everywhere: a special report on
managing information. Economist Newspaper
4. Drowning in numbers - digital data will flood the planet- and help
us understand it better (2011). http://www.economist.com/blogs/
dailychart/2011/11/bigdata-0
5. Lohr S (2012) The age of big data. New York Times, pp 11
6. Yuki N (2011) Following digital breadcrumbs to big data gold.
http://www.npr.org/2011/11/29/142521910/thedigitalbreadcrumbsthat-
lead-to-big-data
7. Yuki N The search for analysts to make sense of big data (2011).
http://www.npr.org/2011/11/30/142893065/the-searchforanalyststo-
make-sense-of-big-data
8. Big data (2008). http://www.nature.com/news/specials/bigdata/
index.html
9. Special online collection: dealing with big data (2011). http://
www.sciencemag.org/site/special/data/
10. Manyika J, McKinsey Global Institute, Chui M, Brown B,
Bughin J, Dobbs R, Roxburgh C, Byers AH (2011) Big data:
the next frontier for innovation, competition, and productivity.
McKinsey Global Institute
11. Mayer-Sch¨onberger V, Cukier K (2013) Big data: a revolution
that will transform how we live, work, and think. Eamon
Dolan/Houghton Mifflin Harcourt
12. Laney D (2001) 3-d data management: controlling data volume,
velocity and variety. META Group Research Note, 6 February
13. Zikopoulos P, Eaton C et al (2011) Understanding big data: analytics
for enterprise class hadoop and streaming data. McGraw-
Hill Osborne Media
14. Meijer E (2011) The world according to linq. Communications
of the ACM 54(10):45–51
15. Beyer M (2011) Gartner says solving big data challenge involves
more than just managing volumes of data. Gartner. http://www.
gartner.com/it/page.jsp
16. O. R. Team (2011) Big data now: current perspectives from
OReilly Radar. OReilly Media
17. Grobelnik M (2012) Big data tutorial. http://videolectures.net/
eswc2012grobelnikbigdata/
18. Ginsberg J, Mohebbi MH, Patel RS, Brammer L, Smolinski MS,
Brilliant L (2008) Detecting influenza epidemics using search
engine query data. Nature 457(7232):1012–1014
19. DeWitt D, Gray J (1992) Parallel database systems: the future of
high performance database systems. Commun ACM35(6):85–98
Mobile Netw Appl (2014) 19:171–209 205
20. Walter T (2009) Teradata past, present, and future. UCI ISG
lecture series on scalable data management
21. Ghemawat S, Gobioff H, Leung S-T (2003) The google file system.
In: ACM SIGOPS Operating Systems Review, vol 37. ACM,
pp 29–43
22. Dean J, Ghemawat S (2008) Mapreduce: simplified data processing
on large clusters. Commun ACM 51(1):107–113
23. Hey AJG, Tansley S, Tolle KM et al (2009) The fourth paradigm:
data-intensive scientific discovery
24. Howard JH, Kazar ML, Menees SG, Nichols DA,
Satyanarayanan M, Sidebotham RN, West MJ (1988) Scale and
performance in a distributed file system. ACM Trans Comput
Syst (TOCS) 6(1):51–81
25. Cattell R (2011) Scalable sql and nosql data stores. ACM SIGMOD
Record 39(4):12–27
26. Labrinidis A, Jagadish HV (2012) Challenges and opportunities
with big data. Proc VLDB Endowment 5(12):2032–2033
27. Chaudhuri S, Dayal U, Narasayya V (2011) An overview
of business intelligence technology. Commun ACM 54(8):
88–98
28. Agrawal D, Bernstein P, Bertino E, Davidson S, Dayal U,
FranklinM, Gehrke J, Haas L, Halevy A, Han J et al (2012) Challenges
and opportunities with big data. A community white paper
developed by leading researches across the United States
29. Sun Y, Chen M, Liu B, Mao S (2013) Far: a fault-avoidant
routing method for data center networks with regular topology.
In: Proceedings of ACM/IEEE symposium on architectures for
networking and communications systems (ANCS’13). ACM
30. Wiki (2013). Applications and organizations using hadoop.
http://wiki.apache.org/hadoop/PoweredBy
31. Bahga A, Madisetti VK (2012) Analyzing massive machine
maintenance data in a computing cloud. IEEE Transac Parallel
Distrib Syst 23(10):1831–1843
32. Gunarathne T, Wu T-L, Choi JY, Bae S-H, Qiu J (2011)
Cloud computing paradigms for pleasingly parallel biomedical
applications. Concurr Comput Prac Experience 23(17):2338–
2354
33. Gantz J, Reinsel D (2010) The digital universe decade-are you
ready. External publication of IDC (Analyse the Future) information
and data, pp 1–16
34. Bryant RE (2011) Data-intensive scalable computing for scientific
applications. Comput Sci Eng 13(6):25–33
35. Wahab MHA, Mohd MNH, Hanafi HF, Mohsin MFM (2008)
Data pre-processing on web server logs for generalized association
rules mining algorithm. World Acad Sci Eng Technol
48:2008
36. Nanopoulos A, Manolopoulos Y, Zakrzewicz M, Morzy T
(2002) Indexing web access-logs for pattern queries. In: Proceedings
of the 4th international workshop on web information and
data management. ACM, pp 63–68
37. Joshi KP, Joshi A, Yesha Y (2003) On using a warehouse to
analyze web logs. Distrib Parallel Databases 13(2):161–180
38. Chandramohan V, Christensen K (2002) A first look at wired
sensor networks for video surveillance systems. In: Proceedings
LCN 2002, 27th annual IEEE conference on local computer
networks. IEEE, pp 728–729
39. Selavo L, Wood A, Cao Q, Sookoor T, Liu H, Srinivasan A, Wu
Y, Kang W, Stankovic J, Young D et al (2007) Luster: wireless
sensor network for environmental research. In: Proceedings of
the 5th international conference on Embedded networked sensor
systems. ACM, pp 103–116
40. Barrenetxea G, Ingelrest F, Schaefer G, Vetterli M, Couach
O, Parlange M (2008) Sensorscope: out-of-the-box environmental
monitoring. In: Information processing in sensor networks,
2008, international conference on IPSN’08. IEEE, pp 332–
343
41. Kim Y, Schmid T, Charbiwala ZM, Friedman J, Srivastava MB
(2008) Nawms: nonintrusive autonomous water monitoring system.
In: Proceedings of the 6th ACM conference on Embedded
network sensor systems. ACM, pp 309–322
42. Kim S, Pakzad S, Culler D, Demmel J, Fenves G, Glaser S,
Turon M (2007) Health monitoring of civil infrastructures using
wireless sensor networks. In Information Processing in Sensor
Networks 2007, 6th International Symposium on IPSN 2007.
IEEE, pp 254–263
43. Ceriotti M, Mottola L, Picco GP, Murphy AL, Guna S, Corra M,
Pozzi M, Zonta D, Zanon P (2009) Monitoring heritage buildings
with wireless sensor networks: the torre aquila deployment.
In: Proceedings of the 2009 International Conference on Information
Processing in Sensor Networks. IEEE Computer Society,
pp 277–288
44. Tolle G, Polastre J, Szewczyk R, Culler D, Turner N, Tu K,
Burgess S, Dawson T, Buonadonna P, Gay D et al (2005) A
macroscope in the redwoods. In: Proceedings of the 3rd international
conference on embedded networked sensor systems. ACM,
pp 51–63
45. Wang F, Liu J (2011) Networked wireless sensor data collection:
issues, challenges, and approaches. IEEE Commun Surv Tutor
13(4):673–687
46. Cho J, Garcia-Molina H (2002) Parallel crawlers. In: Proceedings
of the 11th international conference on World Wide Web. ACM,
pp 124–135
47. Choudhary S, Dincturk ME, Mirtaheri SM, Moosavi A, von
Bochmann G, Jourdan G-V, Onut I-V (2012) Crawling rich internet
applications: the state of the art. In: CASCON. pp 146–
160
48. Ghani N, Dixit S, Wang T-S (2000) On ip-over-wdm integration.
IEEE Commun Mag 38(3):72–84
49. Manchester J, Anderson J, Doshi B, Dravida S, Ip over sonet
(1998) IEEE Commun Mag 36(5):136–142
50. Jinno M, Takara H, Kozicki B (2009) Dynamic optical mesh networks:
drivers, challenges and solutions for the future. In: Optical
communication, 2009, 35th European conference on ECOC’09.
IEEE, pp 1–4
51. Barroso LA, H¨olzle U (2009) The datacenter as a computer: an
introduction to the design of warehouse-scale machines. Synt
Lect Comput Archit 4(1):1–108
52. Armstrong J (2009) Ofdm for optical communications. J Light
Technol 27(3):189–204
53. Shieh W (2011) Ofdm for flexible high-speed optical networks.
J Light Technol 29(10):1560–1577
54. Cisco data center interconnect design and deployment guide
(2010)
55. Greenberg A, Hamilton JR, Jain N, Kandula S, Kim C, Lahiri
P, Maltz DA, Patel P, Sengupta S (2009) Vl2: a scalable and
flexible data center network. In ACM SIGCOMM computer
communication review, vol 39. ACM, pp 51–62
56. Guo C, Lu G, Li D, Wu H, Zhang X, Shi Y, Tian C, Zhang Y,
Lu S (2009) Bcube: a high performance, server-centric network
architecture for modular data centers. ACM SIGCOMM Comput
Commun Rev 39(4):63–74
57. Farrington N, Porter G, Radhakrishnan S, Bazzaz HH,
Subramanya V, Fainman Y, Papen G, Vahdat A (2011) Helios:
a hybrid electrical/optical switch architecture for modular data
centers. ACM SIGCOMM Comput Commun Rev 41(4):339–
350
58. Abu-Libdeh H, Costa P, Rowstron A, O’Shea G, Donnelly A
(2010) Symbiotic routing in future data centers. ACM SIGCOMM
Comput Commun Rev 40(4):51–62
59. Lam C, Liu H, Koley B, Zhao X, Kamalov V, Gill V, Fiber
optic communication technologies: what’s needed for datacenter
network operations (2010) IEEE Commun Mag 48(7):32–39
206 Mobile Netw Appl (2014) 19:171–209
60. Wang G, Andersen DG, Kaminsky M, Papagiannaki K, Ng
TS, Kozuch M, Ryan M (2010) c-through: Part-time optics in
data centers. In: ACM SIGCOMM Computer Communication
Review, vol 40. ACM, pp 327–338
61. Ye X, Yin Y, Yoo SJB, Mejia P, Proietti R, Akella V (2010) Dos:
a scalable optical switch for datacenters. In Proceedings of the
6th ACM/IEEE symposium on architectures for networking and
communications systems. ACM, p 24
62. Singla A, Singh A, Ramachandran K, Xu L, Zhang Y (2010) Proteus:
a topology malleable data center network. In Proceedings
of the 9th ACM SIGCOMM workshop on hot topics in networks.
ACM, p 8
63. Liboiron-Ladouceur O, Cerutti I, Raponi PG, Andriolli N,
Castoldi P (2011) Energy-efficient design of a scalable optical
multiplane interconnection architecture. IEEE J Sel Top
Quantum Electron 17(2):377–383
64. Kodi AK, Louri A (2011) Energy-efficient and bandwidthreconfigurable
photonic networks for high-performance computing
(hpc) systems. IEEE J Sel Top Quantum Electron 17(2):384–
395
65. Zhou X, Zhang Z, Zhu Y, Li Y, Kumar S, Vahdat A, Zhao BY,
Zheng H (2012) Mirror mirror on the ceiling: flexible wireless
links for data centers. ACM SIGCOMM Comput Commun Rev
42(4):443–454
66. Lenzerini M (2002) Data integration: a theoretical perspective.
In: Proceedings of the twenty-first ACM SIGMOD-SIGACTSIGART
symposium on principles of database systems. ACM,
pp 233–246
67. Cafarella MJ, Halevy A, Khoussainova N (2009) Data integration
for the relational web. Proc VLDB Endowment 2(1):1090–
1101
68. Maletic JI, Marcus A (2000) Data cleansing: beyond integrity
analysis. In: IQ. Citeseer, pp 200–209
69. Kohavi R, Mason L, Parekh R, Zheng Z (2004) Lessons and
challenges from mining retail e-commerce data. Mach Learn
57(1-2):83–113
70. Chen H, Ku W-S, Wang H, Sun M-T (2010) Leveraging spatiotemporal
redundancy for rfid data cleansing. In: Proceedings of
the 2010 ACM SIGMOD international conference on management
of data. ACM, pp 51–62
71. Zhao Z, Ng W (2012) A model-based approach for rfid data
stream cleansing. In Proceedings of the 21st ACM international
conference on information and knowledge management. ACM,
pp 862–871
72. Khoussainova N, Balazinska M, Suciu D (2008) Probabilistic
event extraction from rfid data. In: Data Engineering, 2008.
IEEE 24th international conference on ICDE 2008. IEEE, pp
1480–1482
73. Herbert KG, Wang JTL (2007) Biological data cleaning: a case
study. Int J Inf Qual 1(1):60–82
74. Tsai T-H, Lin C-Y (2012) Exploring contextual redundancy in
improving object-based video coding for video sensor networks
surveillance. IEEE Transac Multmed 14(3):669–682
75. Sarawagi S, Bhamidipaty A (2002) Interactive deduplication
using active learning. In Proceedings of the eighth ACM
SIGKDD international conference on knowledge discovery and
data mining. ACM, pp 269–278
76. Kamath U, Compton J, Dogan RI, Jong KD, Shehu A (2012)
An evolutionary algorithm approach for feature generation from
sequence data and its application to dna splice site prediction.
IEEE/ACM Transac Comput Biol Bioinforma (TCBB)
9(5):1387–1398
77. Leung K-S, Lee KH,Wang J-F, Ng EYT, Chan HLY, Tsui SKW,
Mok TSK, Tse PC-H, Sung JJ-Y (2011) Data mining on dna
sequences of hepatitis b virus. IEEE/ACM Transac Comput Biol
Bioinforma 8(2):428–440
78. Huang Z, Shen H, Liu J, Zhou X (2011) Effective data coreduction
for multimedia similarity search. In Proceedings of the
2011 ACM SIGMOD International Conference on Management
of data. ACM, pp 1021–1032
79. Bleiholder J, Naumann F (2008) Data fusion. ACMComput Surv
(CSUR) 41(1):1
80. Brewer EA (2000) Towards robust distributed systems. In:
PODC. p 7
81. Gilbert S, Lynch N (2002) Brewer’s conjecture and the feasibility
of consistent, available, partition-tolerant web services. ACM
SIGACT News 33(2):51–59
82. McKusick MK, Quinlan S (2009) Gfs: eqvolution on fastforward.
ACM Queue 7(7):10
83. Chaiken R, Jenkins B, Larson P-A° , Ramsey B, Shakib D,Weaver
S, Zhou J (2008) Scope: easy and efficient parallel processing
of massive data sets. Proc VLDB Endowment 1(2):1265–
1276
84. Beaver D, Kumar S, Li HC, Sobel J, Vajgel P et al (2010) Finding
a needle in haystack: facebook’s photo storage. In OSDI, vol 10.
pp 1–8
85. DeCandia G, Hastorun D, Jampani M, Kakulapati G, Lakshman
A, Pilchin A, Sivasubramanian S, Vosshall P, Vogels W (2007)
Dynamo: amazon’s highly available key-value store. In: SOSP,
vol 7. pp 205–220
86. Karger D, Lehman E, Leighton T, Panigrahy R, Levine M,
Lewin D (1997) Consistent hashing and random trees: distributed
caching protocols for relieving hot spots on the world wide web.
In: Proceedings of the twenty-ninth annual ACM symposium on
theory of computing. ACM, pp 654–663
87. Chang F, Dean J, Ghemawat S, HsiehWC,Wallach DA, Burrows
M, Chandra T, Fikes A, Gruber RE (2008) Bigtable: a distributed
storage system for structured data. ACM Trans Comput Syst
(TOCS) 26(2):4
88. Burrows M (2006) The chubby lock service for loosely-coupled
distributed systems. In: Proceedings of the 7th symposium on
Operating systems design and implementation. USENIX Association,
pp 335–350
89. Lakshman A, Malik P (2009) Cassandra: structured storage
system on a p2p network. In: Proceedings of the 28th ACM
symposium on principles of distributed computing. ACM,
pp 5–5
90. George L (2011) HBase: the definitive guide. O’Reilly Media Inc
91. Judd D (2008) hypertable-0.9. 0.4-alpha
92. Chodorow K (2013) MongoDB: the definitive guide. O’Reilly
Media Inc
93. Crockford D (2006) The application/json media type for
javascript object notation (json)
94. Murty J (2009) Programming amazon web services: S3, EC2,
SQS, FPS, and SimpleDB. O’Reilly Media Inc
95. Anderson JC, Lehnardt J, Slater N (2010) CouchDB: the definitive
guide. O’Reilly Media Inc
96. Blanas S, Patel JM, Ercegovac V, Rao J, Shekita EJ, Tian Y
(2010) A comparison of join algorithms for log processing in
mapreduce. In: Proceedings of the 2010 ACM SIGMOD international
conference on management of data. ACM, pp 975–
986
97. Yang H-C, Parker DS (2009) Traverse: simplified indexing
on large map-reduce-merge clusters. In: Database systems for
advanced applications. Springer, pp 308–322
98. Pike R, Dorward S, Griesemer R, Quinlan S (2005) Interpreting
the data: parallel analysis with sawzall. Sci Program 13(4):277–
298
99. Gates AF, Natkovich O, Chopra S, Kamath P, Narayanamurthy
SM, Olston C, Reed B, Srinivasan S, Srivastava U (2009) Building
a high-level dataflow system on top of map-reduce: the pig
experience. Proceedings VLDB Endowment 2(2):1414–1425
Mobile Netw Appl (2014) 19:171–209 207
100. Thusoo A, Sarma JS, Jain N, Shao Z, Chakka P, Anthony S,
Liu H, Wyckoff P, Murthy R (2009) Hive: a warehousing solution
over a map-reduce framework. Proc VLDB Endowment
2(2):1626–1629
101. IsardM, BudiuM, Yu Y, Birrell A, Fetterly D (2007) Dryad: distributed
data-parallel programs from sequential building blocks.
ACM SIGOPS Oper Syst Rev 41(3):59–72
102. Yu Y, Isard M, Fetterly D, Budiu M, Erlingsson U´ , Gunda PK,
Currey J (2008) Dryadlinq: a system for general-purpose distributed
data-parallel computing using a high-level language. In:
OSDI, vol 8. pp 1–14
103. Moretti C, Bulosan J, Thain D, Flynn PJ (2008) All-pairs: an
abstraction for data-intensive cloud computing. In: Parallel and
distributed processing, 2008. IEEE international symposium on
IPDPS 2008. IEEE, pp 1–11
104. Malewicz G, Austern MH, Bik AJC, Dehnert JC, Horn I, Leiser
N, Czajkowski G (2010) Pregel: a system for large-scale graph
processing. In: Proceedings of the 2010 ACM SIGMOD international
conference on management of data. ACM, pp 135–146
105. Bu Y, Bill H, Balazinska M, Ernst MD (2010) Haloop: efficient
iterative data processing on large clusters. Proc VLDB
Endowment 3(1-2):285–296
106. Ekanayake J, Li H, Zhang B, Gunarathne T, Bae S-H, Qiu J,
Fox G (2010) Twister: a runtime for iterative mapreduce. In
Proceedings of the 19th ACM international symposium on high
performance distributed computing. ACM, pp 810–818
107. Zaharia M, Chowdhury M, Das T, Dave A, Ma J, McCauley
M, Franklin M, Shenker S, Stoica I (2012) Resilient distributed
datasets: a fault-tolerant abstraction for in-memory cluster computing.
In: Proceedings of the 9th USENIX conference on
networked systems design and implementation. USENIX Association,
pp 2–2
108. Bhatotia P, Wieder A, Rodrigues R, Acar UA, Pasquin R (2011)
Incoop: mapreduce for incremental computations. In: Proceedings
of the 2nd ACM symposium on cloud computing. ACM,
p 7
109. Murray DG, Schwarzkopf M, Smowton C, Smith S,
Madhavapeddy A, Hand S (2011) Ciel: a universal execution
engine for distributed data-flow computing. In: Proceedings of
the 8th USENIX conference on Networked systems design and
implementation. p 9
110. Anderson TW (1958) An introduction to multivariate statistical
analysis, vol 2. Wiley, New York
111. Wu X, Kumar V, Quinlan JR, Ghosh J, Yang Q, Motoda H,
McLachlan GJ, Ng A, Liu B, Philip SY et al (2008) Top 10
algorithms in data mining. Knowl Inf Syst 14(1):1–37
112. What analytics data mining, big data software you used in the
past 12 months for a real project? (2012) http://www.kdnuggets.
com/polls/2012/analytics-data-mining-big-data-software.html
113. Berthold MR, Cebron N, Dill F, Gabriel TR, K¨otter T, Meinl
T, Ohl P, Sieb C, Thiel K, Wiswedel B (2008) KNIME: the
Konstanz information miner. Springer
114. Sallam RL, Richardson J, Hagerty J, Hostmann B (2011) Magic
quadrant for business intelligence platforms. CT, Gartner Group,
Stamford
115. Beyond the PC. Special Report on Personal Technology (2011)
116. Goff SA, Vaughn M, McKay S, Lyons E, Stapleton AE, Gessler
D, Matasci N, Wang L, Hanlon M, Lenards A et al (2011) The
iplant collaborative: cyberinfrastructure for plant biology. Front
Plant Sci 34(2):1–16. doi:10.3389/fpls.2011.00034
117. Baah GK, Gray A, HarroldMJ (2006) On-line anomaly detection
of deployed software: a statistical machine learning approach.
In: Proceedings of the 3rd international workshop on Software
quality assurance. ACM, pp 70–77
118. Moeng M, Melhem R (2010) Applying statistical machine learning
to multicore voltage & frequency scaling. In: Proceedings of
the 7th ACM international conference on computing frontiers.
ACM, pp 277–286
119. Gaber MM, Zaslavsky A, Krishnaswamy S (2005) Mining data
streams: a review. ACM Sigmod Record 34(2):18–26
120. Verykios VS, Bertino E, Fovino IN, Provenza LP, Saygin Y,
Theodoridis Y (2004) State-of-the-art in privacy preserving data
mining. ACM Sigmod Record 33(1):50–57
121. van der Aalst W (2012) Process mining: overview and opportunities.
ACM Transac Manag Inform Syst (TMIS) 3(2):7
122. Manning CD, Sch¨utze H (1999) Foundations of statistical natural
language processing, vol 999. MIT Press
123. Pal SK, Talwar V, Mitra P (2002) Web mining in soft computing
framework, relevance, state of the art and future directions. IEEE
Transac Neural Netw 13(5):1163–1177
124. Chakrabarti S (2000) Data mining for hypertext: a tutorial survey.
ACM SIGKDD Explor Newsl 1(2):1–11
125. Brin S, Page L (1998) The anatomy of a large-scale hypertextual
web search engine. Comput Netw ISDN Syst 30(1):107–117
126. Konopnicki D, Shmueli O (1995) W3qs: a query system for the
world-wide web. In: VLDB, vol 95. pp 54–65
127. Chakrabarti S, Van den Berg M, Dom B (1999) Focused crawling:
a new approach to topic-specific web resource discovery.
Comput Netw 31(11):1623–1640
128. Ding D, Metze F, Rawat S, Schulam PF, Burger S, Younessian
E, Bao L, Christel MG, Hauptmann A (2012) Beyond audio and
video retrieval: towards multimedia summarization. In: Proceedings
of the 2nd ACM international conference on multimedia
retrieval. ACM, pp 2
129. Wang M, Ni B, Hua X-S, Chua T-S (2012) Assistive tagging:
a survey of multimedia tagging with human-computer joint
exploration. ACM Comput Surv (CSUR) 44(4):25
130. Lew MS, Sebe N, Djeraba C, Jain R (2006) Content-based multimedia
information retrieval: state of the art and challenges. ACM
TransMultimed Comput Commun Appl (TOMCCAP) 2(1):1–19
131. Hu W, Xie N, Li L, Zeng X, Maybank S (2011) A survey on
visual content-based video indexing and retrieval. IEEE Trans
Syst Man Cybern Part C Appl Rev 41(6):797–819
132. Park Y-J, Chang K-N (2009) Individual and group behaviorbased
customer profile model for personalized product recommendation.
Expert Syst Appl 36(2):1932–1939
133. Barrag´ans-Mart´inez AB, Costa-Montenegro E, Burguillo JC,
Rey-L´opez M, Mikic-Fonte FA, Peleteiro A (2010) A hybrid
content-based and item-based collaborative filtering approach to
recommend tv programs enhanced with singular value decomposition.
Inf Sci 180(22):4290–4311
134. Naphade M, Smith JR, Tesic J, Chang S-F, Hsu W, Kennedy L,
Hauptmann A, Curtis J (2006) Large-scale concept ontology for
multimedia. IEEE Multimedia 13(3):86–91
135. Ma Z, Yang Y, Cai Y, Sebe N, Hauptmann AG (2012) Knowledge
adaptation for ad hoc multimedia event detection with
few exemplars. In: Proceedings of the 20th ACM international
conference on multimedia. ACM, pp 469–478
136. Hirsch JE (2005) An index to quantify an individual’s scientific
research output. Proc Natl Acad Sci USA 102(46):16569
137. Watts DJ (2004) Six degrees: the science of a connected age.
WW Norton & Company
138. Aggarwal CC (2011) An introduction to social network data
analytics. Springer
139. Scellato S, Noulas A, Mascolo C (2011) Exploiting place features
in link prediction on location-based social networks. In:
Proceedings of the 17th ACM SIGKDD international conference
on Knowledge discovery and data mining. ACM, pp 1046–1054
140. Ninagawa A, Eguchi K (2010) Link prediction using probabilistic
group models of network structure. In: Proceedings of
the 2010 ACM symposium on applied Computing. ACM, pp
1115–1116
208 Mobile Netw Appl (2014) 19:171–209
141. Dunlavy DM, Kolda TG, Acar E (2011) Temporal link prediction
using matrix and tensor factorizations. ACM Transac Knowl
Discov Data (TKDD) 5(2):10
142. Leskovec J, Lang KJ, Mahoney M (2010) Empirical comparison
of algorithms for network community detection. In: Proceedings
of the 19th international conference on World wide web. ACM,
pp 631–640
143. Du N, Wu B, Pei X, Wang B, Xu L (2007) Community detection
in large-scale social networks. In: Proceedings of the 9th
WebKDD and 1st SNA-KDD 2007 workshop onWeb mining and
social network analysis. ACM, pp 16–25
144. Garg S, Gupta T, Carlsson N, Mahanti A (2009) Evolution of an
online social aggregation network: an empirical study. In: Proceedings
of the 9th ACM SIGCOMM conference on Internet
measurement conference. ACM, pp 315–321
145. Allamanis M, Scellato S, Mascolo C (2012) Evolution of a
location-based online social network: analysis and models. In:
Proceedings of the 2012 ACM conference on Internet measurement
conference. ACM, pp 145–158
146. Gong NZ, Xu W, Huang L, Mittal P, Stefanov E, Sekar V, Song
D (2012) Evolution of social-attribute networks: measurements,
modeling, and implications using google+. In: Proceedings of
the 2012 ACM conference on Internet measurement conference.
ACM, pp 131–144
147. Zheleva E, Sharara H, Getoor L (2009) Co-evolution of social
and affiliation networks. In: Proceedings of the 15th ACM
SIGKDD international conference on Knowledge discovery and
data mining. ACM, pp 1007–1016
148. Tang J, Sun J, Wang C, Yang Z (2009) Social influence analysis
in large-scale networks. In: Proceedings of the 15th ACM
SIGKDD international conference on knowledge discovery and
data mining. ACM, pp 807–816
149. Li Y, Chen W, Wang Y, Zhang Z-L (2013) Influence diffusion
dynamics and influence maximization in social networks with
friend and foe relationships. In Proceedings of the sixth ACM
international conference on Web search and data mining. ACM,
pp 657–666
150. Dai W, Chen Y, Xue G-R, Yang Q, Yu Y (2008) Translated
learning: transfer learning across different feature spaces: In:
Advances in neural information processing systems. pp 353–360
151. Cisco Visual Networking Index (2013) Global mobile data traffic
forecast update, 2012–2017 http://www.cisco.com/en.US/
solutions/collateral/ns341/ns525/ns537/ns705/ns827/white paper
c11-520862.html (Son eris¸im: 5 Mayis 2013)
152. Rhee Y, Lee J (2009) On modeling a model of mobile community:
designing user interfaces to support group interaction.
Interactions 16(6):46–51
153. Han J, Lee J-G, Gonzalez H, Li X (2008) Mining massive rfid,
trajectory, and traffic data sets. In: Proceedings of the 14th ACM
SIGKDD international conference on knowledge discovery and
data mining. ACM, p 2
154. Garg MK, Kim D-J, Turaga DS, Prabhakaran B (2010) Multimodal
analysis of body sensor network data streams for
real-time healthcare. In: Proceedings of the international conference
on multimedia information retrieval. ACM, pp 469–
478
155. Park Y, Ghosh J (2012) A probabilistic imputation framework
for predictive analysis using variably aggregated, multi-source
healthcare data. In: Proceedings of the 2nd ACM SIGHIT
international health informatics symposium. ACM, pp 445–
454
156. Tasevski P (2011) Password attacks and generation strategies.
Tartu University: Faculty of Mathematics and Computer
Sciences referencesrp